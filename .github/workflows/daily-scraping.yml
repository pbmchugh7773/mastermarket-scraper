name: Daily Price Scraping

on:
  # Run daily at 2:00 AM UTC (3:00 AM Irish time)
  schedule:
    - cron: '0 2 * * *'
  
  # Allow manual triggering for testing
  workflow_dispatch:
    inputs:
      max_products:
        description: 'Max products per store'
        required: false
        default: '67'
        type: string

jobs:
  scrape-prices:
    name: Scrape ${{ matrix.store }}
    runs-on: ubuntu-latest
    
    strategy:
      # Run all stores in parallel
      matrix:
        store: [Aldi, Tesco, SuperValu]
      
      # Don't cancel other stores if one fails
      fail-fast: false
    
    steps:
      - name: üì• Checkout Repository
        uses: actions/checkout@v4
      
      - name: üêç Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'
      
      - name: üåê Install Chrome Browser
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            google-chrome-stable \
            xvfb
      
      - name: üì¶ Install Python Dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: üîß Setup Chrome Environment
        run: |
          # Set Chrome binary path for Selenium
          export CHROME_BIN=/usr/bin/google-chrome
          echo "CHROME_BIN=/usr/bin/google-chrome" >> $GITHUB_ENV
          
          # Verify Chrome installation
          google-chrome --version
      
      - name: üõí Scrape ${{ matrix.store }} Prices
        env:
          # API Configuration
          API_URL: ${{ secrets.API_URL }}
          SCRAPER_USERNAME: ${{ secrets.SCRAPER_USERNAME }}
          SCRAPER_PASSWORD: ${{ secrets.SCRAPER_PASSWORD }}
          
          # Chrome Configuration
          CHROME_BIN: /usr/bin/google-chrome
          DISPLAY: :99
          
          # Store Configuration
          STORE_NAME: ${{ matrix.store }}
          MAX_PRODUCTS: ${{ github.event.inputs.max_products || '67' }}
        
        run: |
          echo "üè™ Starting ${{ matrix.store }} scraping..."
          echo "üìä Max products: $MAX_PRODUCTS"
          echo "üïê Started at: $(date)"
          
          # Start virtual display for headless Chrome
          Xvfb :99 -screen 0 1920x1080x24 > /dev/null 2>&1 &
          
          # Run the scraper
          python simple_local_to_prod.py \
            --store "$STORE_NAME" \
            --products "$MAX_PRODUCTS"
          
          echo "‚úÖ ${{ matrix.store }} scraping completed at: $(date)"
      
      - name: üìä Upload Results Summary
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: scraping-logs-${{ matrix.store }}-${{ github.run_number }}
          path: |
            *.log
            logs/
          retention-days: 7

  # Summary job that runs after all stores complete
  scraping-summary:
    name: Scraping Summary
    needs: scrape-prices
    runs-on: ubuntu-latest
    if: always()
    
    steps:
      - name: üìä Generate Summary
        run: |
          echo "üéØ Daily Scraping Summary - $(date)"
          echo "=================================="
          
          # Check results from matrix jobs
          if [[ "${{ needs.scrape-prices.result }}" == "success" ]]; then
            echo "‚úÖ All stores completed successfully"
          elif [[ "${{ needs.scrape-prices.result }}" == "failure" ]]; then
            echo "‚ùå Some stores failed - check individual job logs"
          else
            echo "‚ö†Ô∏è Mixed results - check individual job logs"
          fi
          
          echo ""
          echo "üìà Expected Results:"
          echo "‚Ä¢ Aldi: ~67 products in ~6 minutes"  
          echo "‚Ä¢ Tesco: ~67 products in ~2.2 hours"
          echo "‚Ä¢ SuperValu: ~67 products in ~2.2 hours"
          echo "‚Ä¢ Total: ~200 products updated"
          echo ""
          echo "üîó Check results at: https://www.mastermarketapp.com/products"
      
      - name: üö® Notify on Failure
        if: needs.scrape-prices.result == 'failure'
        run: |
          echo "‚ö†Ô∏è SCRAPING FAILURE DETECTED"
          echo "Please check the individual job logs for details."
          echo "Common causes:"
          echo "‚Ä¢ API authentication issues"
          echo "‚Ä¢ Website anti-bot measures"
          echo "‚Ä¢ Network connectivity problems"
          echo "‚Ä¢ Chrome/Selenium configuration issues"
          echo ""
          echo "üîß Troubleshooting:"
          echo "‚Ä¢ Verify GitHub Secrets are set correctly"
          echo "‚Ä¢ Check MasterMarket API status"
          echo "‚Ä¢ Review individual store job logs"
          echo "‚Ä¢ Consider manual re-run if temporary issue"